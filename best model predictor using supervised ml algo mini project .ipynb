{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"breast_cancer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>843786</td>\n",
       "      <td>M</td>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>...</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>844359</td>\n",
       "      <td>M</td>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>...</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>84458202</td>\n",
       "      <td>M</td>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>...</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>844981</td>\n",
       "      <td>M</td>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>...</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>84501001</td>\n",
       "      <td>M</td>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>...</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "5    843786         M        12.45         15.70           82.57      477.1   \n",
       "6    844359         M        18.25         19.98          119.60     1040.0   \n",
       "7  84458202         M        13.71         20.83           90.20      577.9   \n",
       "8    844981         M        13.00         21.82           87.50      519.8   \n",
       "9  84501001         M        12.46         24.04           83.97      475.9   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760         0.30010              0.14710   \n",
       "1          0.08474           0.07864         0.08690              0.07017   \n",
       "2          0.10960           0.15990         0.19740              0.12790   \n",
       "3          0.14250           0.28390         0.24140              0.10520   \n",
       "4          0.10030           0.13280         0.19800              0.10430   \n",
       "5          0.12780           0.17000         0.15780              0.08089   \n",
       "6          0.09463           0.10900         0.11270              0.07400   \n",
       "7          0.11890           0.16450         0.09366              0.05985   \n",
       "8          0.12730           0.19320         0.18590              0.09353   \n",
       "9          0.11860           0.23960         0.22730              0.08543   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "5  ...          23.75           103.40       741.6            0.1791   \n",
       "6  ...          27.66           153.20      1606.0            0.1442   \n",
       "7  ...          28.14           110.60       897.0            0.1654   \n",
       "8  ...          30.73           106.20       739.3            0.1703   \n",
       "9  ...          40.68            97.65       711.4            0.1853   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "5             0.5249           0.5355                0.1741          0.3985   \n",
       "6             0.2576           0.3784                0.1932          0.3063   \n",
       "7             0.3682           0.2678                0.1556          0.3196   \n",
       "8             0.5401           0.5390                0.2060          0.4378   \n",
       "9             1.0580           1.1050                0.2210          0.4366   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "5                  0.12440          NaN  \n",
       "6                  0.08368          NaN  \n",
       "7                  0.11510          NaN  \n",
       "8                  0.10720          NaN  \n",
       "9                  0.20750          NaN  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop([\"id\",\"Unnamed: 32\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUMMARISING THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 31)\n",
      "       radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
      "count   569.000000    569.000000      569.000000   569.000000   \n",
      "mean     14.127292     19.289649       91.969033   654.889104   \n",
      "std       3.524049      4.301036       24.298981   351.914129   \n",
      "min       6.981000      9.710000       43.790000   143.500000   \n",
      "25%      11.700000     16.170000       75.170000   420.300000   \n",
      "50%      13.370000     18.840000       86.240000   551.100000   \n",
      "75%      15.780000     21.800000      104.100000   782.700000   \n",
      "max      28.110000     39.280000      188.500000  2501.000000   \n",
      "\n",
      "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "count       569.000000        569.000000      569.000000           569.000000   \n",
      "mean          0.096360          0.104341        0.088799             0.048919   \n",
      "std           0.014064          0.052813        0.079720             0.038803   \n",
      "min           0.052630          0.019380        0.000000             0.000000   \n",
      "25%           0.086370          0.064920        0.029560             0.020310   \n",
      "50%           0.095870          0.092630        0.061540             0.033500   \n",
      "75%           0.105300          0.130400        0.130700             0.074000   \n",
      "max           0.163400          0.345400        0.426800             0.201200   \n",
      "\n",
      "       symmetry_mean  fractal_dimension_mean  ...  radius_worst  \\\n",
      "count     569.000000              569.000000  ...    569.000000   \n",
      "mean        0.181162                0.062798  ...     16.269190   \n",
      "std         0.027414                0.007060  ...      4.833242   \n",
      "min         0.106000                0.049960  ...      7.930000   \n",
      "25%         0.161900                0.057700  ...     13.010000   \n",
      "50%         0.179200                0.061540  ...     14.970000   \n",
      "75%         0.195700                0.066120  ...     18.790000   \n",
      "max         0.304000                0.097440  ...     36.040000   \n",
      "\n",
      "       texture_worst  perimeter_worst   area_worst  smoothness_worst  \\\n",
      "count     569.000000       569.000000   569.000000        569.000000   \n",
      "mean       25.677223       107.261213   880.583128          0.132369   \n",
      "std         6.146258        33.602542   569.356993          0.022832   \n",
      "min        12.020000        50.410000   185.200000          0.071170   \n",
      "25%        21.080000        84.110000   515.300000          0.116600   \n",
      "50%        25.410000        97.660000   686.500000          0.131300   \n",
      "75%        29.720000       125.400000  1084.000000          0.146000   \n",
      "max        49.540000       251.200000  4254.000000          0.222600   \n",
      "\n",
      "       compactness_worst  concavity_worst  concave points_worst  \\\n",
      "count         569.000000       569.000000            569.000000   \n",
      "mean            0.254265         0.272188              0.114606   \n",
      "std             0.157336         0.208624              0.065732   \n",
      "min             0.027290         0.000000              0.000000   \n",
      "25%             0.147200         0.114500              0.064930   \n",
      "50%             0.211900         0.226700              0.099930   \n",
      "75%             0.339100         0.382900              0.161400   \n",
      "max             1.058000         1.252000              0.291000   \n",
      "\n",
      "       symmetry_worst  fractal_dimension_worst  \n",
      "count      569.000000               569.000000  \n",
      "mean         0.290076                 0.083946  \n",
      "std          0.061867                 0.018061  \n",
      "min          0.156500                 0.055040  \n",
      "25%          0.250400                 0.071460  \n",
      "50%          0.282200                 0.080040  \n",
      "75%          0.317900                 0.092080  \n",
      "max          0.663800                 0.207500  \n",
      "\n",
      "[8 rows x 30 columns]\n",
      "\n",
      "diagnosis\n",
      "B    357\n",
      "M    212\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "diagnosis                  False\n",
       "radius_mean                False\n",
       "texture_mean               False\n",
       "perimeter_mean             False\n",
       "area_mean                  False\n",
       "smoothness_mean            False\n",
       "compactness_mean           False\n",
       "concavity_mean             False\n",
       "concave points_mean        False\n",
       "symmetry_mean              False\n",
       "fractal_dimension_mean     False\n",
       "radius_se                  False\n",
       "texture_se                 False\n",
       "perimeter_se               False\n",
       "area_se                    False\n",
       "smoothness_se              False\n",
       "compactness_se             False\n",
       "concavity_se               False\n",
       "concave points_se          False\n",
       "symmetry_se                False\n",
       "fractal_dimension_se       False\n",
       "radius_worst               False\n",
       "texture_worst              False\n",
       "perimeter_worst            False\n",
       "area_worst                 False\n",
       "smoothness_worst           False\n",
       "compactness_worst          False\n",
       "concavity_worst            False\n",
       "concave points_worst       False\n",
       "symmetry_worst             False\n",
       "fractal_dimension_worst    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data.describe())\n",
    "print()\n",
    "print(data.groupby(\"diagnosis\").size())\n",
    "data.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALLING 6 ALGOS\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#for our accuracy score\n",
    "from sklearn.model_selection import cross_val_score as cvs\n",
    "from sklearn.model_selection import StratifiedKFold as skf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.drop([\"diagnosis\"],axis=1)\n",
    "y=data.diagnosis\n",
    "x_train,x_validation,y_train,y_validation=train_test_split(x,y,test_size=0.30,random_state=20,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[]\n",
    "models.append((\"LR\",LogisticRegression()))\n",
    "models.append((\"CART\",DecisionTreeClassifier()))\n",
    "models.append((\"KNN\",KNeighborsClassifier()))\n",
    "models.append((\"NB\",GaussianNB()))\n",
    "models.append((\"SVM\",SVC(gamma=1)))\n",
    "models.append((\"LDA\",LinearDiscriminantAnalysis()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\U\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\U\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\U\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\U\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\U\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\U\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\U\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\U\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\U\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\U\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR : 94.48076923076924% mean , (3.834110417762508%) std \n",
      "CART : 92.46794871794873% mean , (4.176147989662026%) std \n",
      "KNN : 92.21794871794872% mean , (3.4258847602528215%) std \n",
      "NB : 93.97435897435898% mean , (3.3839840125954543%) std \n",
      "SVM : 62.82051282051283% mean , (0.6410256410256432%) std \n",
      "LDA : 94.9871794871795% mean , (2.958289926619907%) std \n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "names=[]\n",
    "res=[]\n",
    "for name,model in models:\n",
    "    kfold=skf(n_splits=10)\n",
    "    cv_result=cvs(model,x_train,y_train,cv=kfold,scoring=\"accuracy\")\n",
    "    results.append(cv_result)\n",
    "    names.append(name)\n",
    "    res.append(cv_result.mean())\n",
    "    #print(\"%s : %f  (%f)\" %(name,cv_result.mean(),cv_result.std()))\n",
    "    print(\"{} : {}% mean , ({}%) std \".format(name,cv_result.mean()*100,cv_result.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.ylim(.60,0.98)\n",
    "plt.bar(names,res,width=0.6,edgecolor=\"red\",color=\"black\")\n",
    "plt.title(\"Algorithm Comparision\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
